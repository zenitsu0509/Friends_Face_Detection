{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dYFDj84S7mkj"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qRh4x7tq7bk"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XjqYrRuYqpDp"
      },
      "outputs": [],
      "source": [
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1WFOY8olqrbP"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "csxw4fCBq2LB"
      },
      "outputs": [],
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "          const div = document.createElement('div');\n",
        "          const capture = document.createElement('button');\n",
        "          capture.textContent = 'Capture';\n",
        "          div.appendChild(capture);\n",
        "\n",
        "          const video = document.createElement('video');\n",
        "          video.style.display = 'block';\n",
        "          const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "          document.body.appendChild(div);\n",
        "          div.appendChild(video);\n",
        "          video.srcObject = stream;\n",
        "          await video.play();\n",
        "\n",
        "          // Resize the output to fit the video element.\n",
        "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "          // Wait for Capture to be clicked.\n",
        "          await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "          // Create canvas and set dimensions to 640x640\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = 640;\n",
        "          canvas.height = 640;\n",
        "\n",
        "          // Resize the video to fit the canvas size (cropping may occur)\n",
        "          const context = canvas.getContext('2d');\n",
        "          context.drawImage(video, 0, 0, 640, 640);  // Draw the video on the 640x640 canvas\n",
        "\n",
        "          stream.getVideoTracks()[0].stop();\n",
        "          div.remove();\n",
        "          return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    # get OpenCV format image\n",
        "    img = js_to_image(data)\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    print(gray.shape)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    # Save the grayscale image\n",
        "    cv2.imwrite(filename, gray)\n",
        "\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "OEUKcpKGq40D",
        "outputId": "da8114d8-a304-4d9c-c3e9-a31403caa7cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "          const div = document.createElement('div');\n",
              "          const capture = document.createElement('button');\n",
              "          capture.textContent = 'Capture';\n",
              "          div.appendChild(capture);\n",
              "\n",
              "          const video = document.createElement('video');\n",
              "          video.style.display = 'block';\n",
              "          const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "          document.body.appendChild(div);\n",
              "          div.appendChild(video);\n",
              "          video.srcObject = stream;\n",
              "          await video.play();\n",
              "\n",
              "          // Resize the output to fit the video element.\n",
              "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "          // Wait for Capture to be clicked.\n",
              "          await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "          // Create canvas and set dimensions to 640x640\n",
              "          const canvas = document.createElement('canvas');\n",
              "          canvas.width = 640;\n",
              "          canvas.height = 640;\n",
              "\n",
              "          // Resize the video to fit the canvas size (cropping may occur)\n",
              "          const context = canvas.getContext('2d');\n",
              "          context.drawImage(video, 0, 0, 640, 640);  // Draw the video on the 640x640 canvas\n",
              "\n",
              "          stream.getVideoTracks()[0].stop();\n",
              "          div.remove();\n",
              "          return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 640)\n",
            "Saved to photo.jpg\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  filename = take_photo('photo.jpg')\n",
        "  print('Saved to {}'.format(filename))\n",
        "except Exception as err:\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "uOZ7SqRPsKat",
        "outputId": "a240f90b-d29e-4c35-e949-04bb157c39d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 1 Himanshu, 20.9ms\n",
            "Speed: 2.7ms preprocess, 20.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'imh.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained model\n",
        "model = YOLO('/content/new_trained_model_face.pt')\n",
        "\n",
        "# Load the image\n",
        "image_path = filename  # Provide the path to your image\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.resize(image, (256,256)) # Use cv2.resize to resize the image\n",
        "\n",
        "# Perform prediction\n",
        "results = model(image)\n",
        "results = results[0]\n",
        "results.show()\n",
        "results.save('imh.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeV52T4V7vr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}